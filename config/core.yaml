hydra:
  run:
    dir: /media/dmitry/data/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job_logging:
    handlers:
      file:
        filename: ${hydra.job.name}_${distributed.local_rank}.log

defaults:
  - data: default
  - model: samwise
  - loss: tripple
  - lr_scheduler: one-cycle
  - optimizer: adam_w

general:
  gpu: 1
  seed: 333

distributed:
  backend: null
  local_rank: 0
  url: env://

data:
  train:
    type: hdf5
    dir: /media/dmitry/other/dfdc-crops/hdf5
    chunks: 5 - 50
    dir_list: ''
    sample:
      frames: 10
      real_fake_ratio: 3.33
      sparse_frames_prob: 0.5
    # loader setting are per each GPU
    loader:
      batch_size: 16
      workers: 1
  val:
    type: hdf5
    dir: /media/dmitry/other/dfdc-crops/hdf5
    chunks: 0, 1, 2, 3, 4
    sample:
      frames: 10
      real_fake_ratio: 3.33
      sparse_frames_prob: 1.0
    loader:
      batch_size: 16
      workers: 1

optimizer:
  step_interval: 2

train:
  epochs: 100
  epoch_length: 15000
  checkpoints:
    load: null
    base_dir: null
    interval_epoch: 1
    interval_iteration: 500
    max_checkpoints: 20

validate:
  interval: 1

logging:
  model: true
  iter_freq: 100
