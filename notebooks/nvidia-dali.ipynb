{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import nvidia.dali as dali\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/dmitry/projects/dfdc'\n",
    "SRC_DIR = os.path.join(BASE_DIR, 'src')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data/dfdc-videos')\n",
    "\n",
    "sys.path.insert(0, SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.utils import read_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoPipe(dali.pipeline.Pipeline):\n",
    "    def __init__(self, file_list: str, seq_len=30, stride=10, \n",
    "                 batch_size=1, num_threads=1, device_id=0):\n",
    "        super(VideoPipe, self).__init__(\n",
    "            batch_size, num_threads, device_id, seed=3)\n",
    "        \n",
    "        self.input = dali.ops.VideoReader(\n",
    "            device='gpu', file_list=file_list, sequence_length=seq_len, \n",
    "            stride=stride, shard_id=0, num_shards=1)\n",
    "\n",
    "    def define_graph(self):\n",
    "        output, labels = self.input(name='reader')\n",
    "        return output, labels\n",
    "    \n",
    "    \n",
    "def get_file_list(df: pd.DataFrame, start: int, end: int, \n",
    "                  base_dir:str=DATA_DIR) -> List[str]:\n",
    "    path_fn = lambda row: os.path.join(base_dir, row.dir, row.name)\n",
    "    return df.iloc[start:end].apply(path_fn, axis=1).values.tolist()\n",
    "\n",
    "\n",
    "def write_file_list(files, path='./file_list.txt'):    \n",
    "    with open(path, mode='w') as h:\n",
    "        for i, f in enumerate(files):\n",
    "            h.write(f'{f} {i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_diff_chunks(\n",
    "        df: pd.DataFrame, base_dir:str=DATA_DIR) -> List[str]:\n",
    "    chunks = df['dir'].unique()\n",
    "    files = []\n",
    "    for chunk in chunks:\n",
    "        row = df[df['dir']==chunk].iloc[0]\n",
    "        path = os.path.join(base_dir, row.dir, row.name)\n",
    "        files.append(path)\n",
    "    return files\n",
    "\n",
    "\n",
    "def build_iter(files):\n",
    "    pipe = VideoPipe(files, seq_len=30, stride=11)\n",
    "    pipe.build()\n",
    "    data_iter = DALIGenericIterator([pipe], ['images'], len(files), dynamic_shape=True)\n",
    "    return data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_labels(DATA_DIR, chunk_dirs=['dfdc_train_part_49'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = get_files_diff_chunks(df)\n",
    "start = 2650\n",
    "end = start + 350\n",
    "files = get_file_list(df, start, end)\n",
    "list_path = './lel_kek_cheburek.txt'\n",
    "write_file_list(files, path=list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = VideoPipe(list_path, seq_len=30, stride=10, device_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.build()\n",
    "num_samples_read = pipe.epoch_size('reader')\n",
    "\n",
    "num_samples_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_iter = DALIGenericIterator(\n",
    "    [pipe], ['images', 'label'], num_samples_read, dynamic_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_sample(data_iter):\n",
    "    out = next(data_iter)[0]\n",
    "    return out['images'].cpu().numpy(), out['label'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idxs = [0,1,2,14,15,16,27,28,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 /home/dmitry/projects/dfdc/data/dfdc-videos/dfdc_train_part_49/azmheosoed.mp4\n"
     ]
    }
   ],
   "source": [
    "images, idx = next_sample(data_iter)\n",
    "print(idx, files[idx])\n",
    "# show_images(images[0, frame_idxs], cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(0, SRC_DIR)\n",
    "# from sample.reader import VideoReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = VideoReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(i)\n",
    "# sample, frames = reader.read_frames(files[i], 30)\n",
    "# num_frames = len(sample)\n",
    "# print(f'Num frames: {num_frames}')\n",
    "# frame_idxs_fixed = [f for f in frame_idxs if f < len(sample)]\n",
    "# show_images(sample[frame_idxs_fixed], cols=3)\n",
    "# i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs224n]",
   "language": "python",
   "name": "conda-env-cs224n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
