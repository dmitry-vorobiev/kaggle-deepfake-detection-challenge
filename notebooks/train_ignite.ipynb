{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.1, ignite: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import ignite\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torchvision import transforms as T\n",
    "from typing import Callable, Iterable, List, Tuple\n",
    "\n",
    "print(f\"torch: {torch.__version__}, ignite: {ignite.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/dmitry/projects/dfdc'\n",
    "SRC_DIR = os.path.join(BASE_DIR, 'src')\n",
    "HDF5_DIR = '/media/dmitry/other/dfdc-crops/hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src\n",
    "sys.path.insert(0, os.path.join(BASE_DIR, 'vendors/Pytorch_Retinaface'))\n",
    "sys.path.insert(0, SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.hdf5 import HDF5Dataset\n",
    "from dataset.sample import FrameSampler, BalancedSampler\n",
    "from model.detector import basic_detector_256\n",
    "from model.loss import combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualise import show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(bs: int, num_frames: int, real_fake_ratio: float, \n",
    "                      p_sparse_frames: float, chunks: Iterable[int]\n",
    "                     ) -> torch.utils.data.DataLoader:\n",
    "    dirs = [f'dfdc_train_part_{i}' for i in chunks]\n",
    "    \n",
    "    sampler = FrameSampler(num_frames, \n",
    "                           real_fake_ratio=real_fake_ratio, \n",
    "                           p_sparse=p_sparse_frames)\n",
    "    tfms = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    ds = HDF5Dataset(HDF5_DIR, size=(num_frames, 256), \n",
    "                     sampler=sampler, x_tfms=tfms, sub_dirs=dirs)\n",
    "    print('Num samples: {}'.format(len(ds)))\n",
    "    \n",
    "    batch_sampler = torch.utils.data.BatchSampler(\n",
    "        BalancedSampler(ds),\n",
    "        batch_size=bs, \n",
    "        drop_last=True\n",
    "    )\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_sampler=batch_sampler)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 61779\n"
     ]
    }
   ],
   "source": [
    "train_dl = create_dataloader(\n",
    "    bs=12, \n",
    "    num_frames=10, \n",
    "    real_fake_ratio=100/30, \n",
    "    p_sparse_frames=0.75, \n",
    "    chunks=range(5,30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 7937\n"
     ]
    }
   ],
   "source": [
    "valid_dl = create_dataloader(\n",
    "    bs=12, \n",
    "    num_frames=10, \n",
    "    real_fake_ratio=100/30, \n",
    "    p_sparse_frames=1., \n",
    "    chunks=range(0,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Conv3D pooling: 2 layers\n"
     ]
    }
   ],
   "source": [
    "model = basic_detector_256()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optim, milestones=[9], gamma=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = Tuple[FloatTensor, LongTensor]\n",
    "\n",
    "\n",
    "def prepare_batch(batch: Batch) -> Batch:\n",
    "    x, y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train(trainer: Engine, batch: Batch) -> int:\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    x, y = prepare_batch(batch)\n",
    "    out = model(x, y)\n",
    "    loss = combined_loss(out, x, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    y_hat = (out[-1] > 0.5).float()\n",
    "    return loss.item(), y_hat, y\n",
    "\n",
    "\n",
    "def validate(trainer: Engine, batch: Batch) -> int:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = prepare_batch(batch)\n",
    "        out = model(x, y)\n",
    "        loss = combined_loss(out, x, y)\n",
    "    y_hat = (out[-1] > 0.5).float()\n",
    "    return loss.item(), y_hat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Engine(train)\n",
    "evaluator = Engine(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(output_transform=lambda x: [x[1], x[2]])\n",
    "accuracy.attach(trainer,   'acc')\n",
    "accuracy.attach(evaluator, 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_iter(engine: Engine, title: str) -> None:\n",
    "    iteration = engine.state.iteration\n",
    "    epoch = trainer.state.epoch\n",
    "    loss = engine.state.output[0]\n",
    "    print(\"{:>5} | ep: {}, it: {}, loss: {:.5f}\".format(\n",
    "        title, epoch, iteration, loss))\n",
    "    \n",
    "    \n",
    "def log_epoch(engine: Engine, title: str) -> None:\n",
    "    epoch = trainer.state.epoch\n",
    "    acc = engine.state.metrics['acc']\n",
    "    print(\"{:>5} | ep: {}, acc: {:.3f}\\n\".format(title, epoch, acc))\n",
    "    \n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=1))\n",
    "def log_train_iter(engine: Engine) -> None:\n",
    "    log_iter(engine, 'train')\n",
    "    \n",
    "    \n",
    "@evaluator.on(Events.ITERATION_COMPLETED(every=1))\n",
    "def log_val_iter(engine: Engine) -> None:\n",
    "    log_iter(engine, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def evaluate(trainer):\n",
    "    with evaluator.add_event_handler(Events.COMPLETED, log_epoch, 'val'):\n",
    "        evaluator.run(valid_dl, epoch_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | ep: 1, it: 1, loss: 1.72871\n",
      "train | ep: 1, it: 2, loss: 1.85537\n",
      "train | ep: 1, it: 3, loss: 1.81833\n",
      "train | ep: 1, it: 4, loss: 1.71735\n",
      "train | ep: 1, it: 5, loss: 1.74818\n",
      "  val | ep: 1, it: 1, loss: 1.71932\n",
      "  val | ep: 1, it: 2, loss: 1.66894\n",
      "  val | ep: 1, acc: 0.417\n",
      "\n",
      "train | ep: 2, it: 6, loss: 1.78472\n",
      "train | ep: 2, it: 7, loss: 1.75002\n",
      "train | ep: 2, it: 8, loss: 1.73071\n",
      "train | ep: 2, it: 9, loss: 1.66770\n",
      "train | ep: 2, it: 10, loss: 2.05835\n",
      "  val | ep: 2, it: 1, loss: 1.73405\n",
      "  val | ep: 2, it: 2, loss: 1.76036\n",
      "  val | ep: 2, acc: 0.583\n",
      "\n",
      "train | ep: 3, it: 11, loss: 1.77715\n",
      "train | ep: 3, it: 12, loss: 1.75383\n",
      "train | ep: 3, it: 13, loss: 1.68536\n",
      "train | ep: 3, it: 14, loss: 1.71176\n",
      "train | ep: 3, it: 15, loss: 1.73357\n",
      "  val | ep: 3, it: 1, loss: 1.69722\n",
      "  val | ep: 3, it: 2, loss: 1.73346\n",
      "  val | ep: 3, acc: 0.417\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 15\n",
       "\tepoch: 3\n",
       "\tepoch_length: 5\n",
       "\tmax_epochs: 3\n",
       "\toutput: <class 'tuple'>\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: 12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_dl, max_epochs=3, epoch_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = iter(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = batch[0].permute(0, 1, 3, 4, 2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(images[:,1], cols=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle] *",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
