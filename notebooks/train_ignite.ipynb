{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.1, ignite: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import ignite\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from torch import FloatTensor, LongTensor, Tensor\n",
    "from torchvision import transforms as T\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable, Dict, Iterable, List, Tuple\n",
    "\n",
    "print(f\"torch: {torch.__version__}, ignite: {ignite.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/dmitry/projects/dfdc'\n",
    "SRC_DIR = os.path.join(BASE_DIR, 'src')\n",
    "HDF5_DIR = '/media/dmitry/other/dfdc-crops/hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src\n",
    "sys.path.insert(0, os.path.join(BASE_DIR, 'vendors/Pytorch_Retinaface'))\n",
    "sys.path.insert(0, SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.hdf5 import HDF5Dataset\n",
    "from dataset.sample import FrameSampler, BalancedSampler\n",
    "from model.detector import basic_detector_256, DetectorOut\n",
    "from model.loss import combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualise import show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = Tuple[FloatTensor, LongTensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(bs: int, num_frames: int, real_fake_ratio: float, \n",
    "                      p_sparse_frames: float, chunks: Iterable[int]\n",
    "                     ) -> torch.utils.data.DataLoader:\n",
    "    dirs = [f'dfdc_train_part_{i}' for i in chunks]\n",
    "    \n",
    "    sampler = FrameSampler(num_frames, \n",
    "                           real_fake_ratio=real_fake_ratio, \n",
    "                           p_sparse=p_sparse_frames)\n",
    "    tfms = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    ds = HDF5Dataset(HDF5_DIR, size=(num_frames, 256), \n",
    "                     sampler=sampler, x_tfms=tfms, sub_dirs=dirs)\n",
    "    print('Num samples: {}'.format(len(ds)))\n",
    "    \n",
    "    batch_sampler = torch.utils.data.BatchSampler(\n",
    "        BalancedSampler(ds),\n",
    "        batch_size=bs, \n",
    "        drop_last=True\n",
    "    )\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_sampler=batch_sampler)\n",
    "    return dl\n",
    "\n",
    "\n",
    "def prepare_batch(batch: Batch) -> Batch:\n",
    "    x, y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 61779\n"
     ]
    }
   ],
   "source": [
    "train_dl = create_dataloader(\n",
    "    bs=12, \n",
    "    num_frames=10, \n",
    "    real_fake_ratio=100/30, \n",
    "    p_sparse_frames=0.75, \n",
    "    chunks=range(5,30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 7937\n"
     ]
    }
   ],
   "source": [
    "valid_dl = create_dataloader(\n",
    "    bs=12, \n",
    "    num_frames=10, \n",
    "    real_fake_ratio=100/30, \n",
    "    p_sparse_frames=1., \n",
    "    chunks=range(0,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Conv3D pooling: 2 layers\n"
     ]
    }
   ],
   "source": [
    "model = basic_detector_256()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(12, 3, 10, 256, 256, device=device)\n",
    "y = torch.randint(0, 2, (12,), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8204562229471f95658c4abea4e21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 30s, sys: 6.26 s, total: 2min 36s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = iter(train_dl)\n",
    "data = list(map(lambda _: next(data), tqdm(range(100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbf3dcc432d442fb93fb2434f9b96f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 6.16 s, sys: 1.72 s, total: 7.88 s\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for batch in tqdm(data):\n",
    "    batch = prepare_batch(batch)\n",
    "    out = model(*batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 - 7.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optim, milestones=[9], gamma=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_outs(batch: Batch, model_out: DetectorOut, \n",
    "                loss: FloatTensor) -> Dict[str, Tensor]:\n",
    "    out = {'loss': loss.item(),\n",
    "           'y_pred': (model_out[-1] >= 0.5).float(),\n",
    "           'y_true': batch[-1]}\n",
    "    return out\n",
    "\n",
    "\n",
    "def train(trainer: Engine, batch: Batch) -> int:\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    x, y = prepare_batch(batch)\n",
    "    out = model(x, y)\n",
    "    loss = combined_loss(out, x, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return gather_outs(batch, out, loss)\n",
    "\n",
    "\n",
    "def validate(trainer: Engine, batch: Batch) -> int:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = prepare_batch(batch)\n",
    "        out = model(x, y)\n",
    "        loss = combined_loss(out, x, y)\n",
    "    return gather_outs(batch, out, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Engine(train)\n",
    "evaluator = Engine(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(output_transform=lambda out: [out['y_pred'], out['y_true']])\n",
    "accuracy.attach(trainer,   'acc')\n",
    "accuracy.attach(evaluator, 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_iter(engine: Engine, title: str) -> None:\n",
    "    epoch = trainer.state.epoch\n",
    "    iteration = engine.state.iteration\n",
    "    loss = engine.state.output['loss']\n",
    "    print(\"{:>5} | ep: {}, it: {}, loss: {:.5f}\".format(\n",
    "        title, epoch, iteration, loss))\n",
    "    \n",
    "    \n",
    "def log_epoch(engine: Engine, title: str) -> None:\n",
    "    epoch = trainer.state.epoch\n",
    "    metrics = engine.state.metrics\n",
    "    print(\"{:>5} | ep: {}, acc: {:.3f}\\n\".format(\n",
    "        title, epoch, metrics['acc']))\n",
    "\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=1))\n",
    "def log_train_iter(engine: Engine) -> None:\n",
    "    log_iter(engine, 'train')\n",
    "    \n",
    "    \n",
    "@evaluator.on(Events.ITERATION_COMPLETED(every=1))\n",
    "def log_val_iter(engine: Engine) -> None:\n",
    "    log_iter(engine, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def evaluate(trainer):\n",
    "    with evaluator.add_event_handler(Events.COMPLETED, log_epoch, 'val'):\n",
    "        evaluator.run(valid_dl, epoch_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | ep: 1, it: 1, loss: 1.71473\n",
      "train | ep: 1, it: 2, loss: 1.69912\n",
      "train | ep: 1, it: 3, loss: 1.71272\n",
      "train | ep: 1, it: 4, loss: 1.72062\n",
      "train | ep: 1, it: 5, loss: 1.70535\n",
      "  val | ep: 1, it: 1, loss: 1.73790\n",
      "  val | ep: 1, it: 2, loss: 1.71583\n",
      "  val | ep: 1, acc: 0.417\n",
      "\n",
      "train | ep: 2, it: 6, loss: 1.71046\n",
      "train | ep: 2, it: 7, loss: 1.74335\n",
      "train | ep: 2, it: 8, loss: 1.70676\n",
      "train | ep: 2, it: 9, loss: 1.67067\n",
      "train | ep: 2, it: 10, loss: 1.85039\n",
      "  val | ep: 2, it: 1, loss: 1.69345\n",
      "  val | ep: 2, it: 2, loss: 1.69110\n",
      "  val | ep: 2, acc: 0.625\n",
      "\n",
      "train | ep: 3, it: 11, loss: 1.74073\n",
      "train | ep: 3, it: 12, loss: 1.78620\n",
      "train | ep: 3, it: 13, loss: 1.65802\n",
      "train | ep: 3, it: 14, loss: 1.71624\n",
      "train | ep: 3, it: 15, loss: 1.69114\n",
      "  val | ep: 3, it: 1, loss: 1.67884\n",
      "  val | ep: 3, it: 2, loss: 1.71138\n",
      "  val | ep: 3, acc: 0.417\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 15\n",
       "\tepoch: 3\n",
       "\tepoch_length: 5\n",
       "\tmax_epochs: 3\n",
       "\toutput: <class 'dict'>\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: 12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_dl, max_epochs=3, epoch_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = iter(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = batch[0].permute(0, 2, 3, 4, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(images[:,1], cols=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle] *",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
