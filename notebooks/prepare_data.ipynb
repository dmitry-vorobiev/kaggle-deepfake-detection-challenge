{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from numba import jit, njit\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/dmitry/projects/dfdc'\n",
    "SRC_DIR = os.path.join(BASE_DIR, 'src')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data/dfdc-videos')\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'data/dfdc-crops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import ops\n",
    "\n",
    "import nvidia.dali as dali\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "# src\n",
    "sys.path.insert(0, SRC_DIR)\n",
    "from sample.reader import VideoReader\n",
    "from dataset.utils import read_labels\n",
    "\n",
    "# Pytorch_Retinaface\n",
    "sys.path.insert(0, os.path.join(BASE_DIR, 'Pytorch_Retinaface'))\n",
    "from data import cfg_mnet\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from models.retinaface import RetinaFace\n",
    "from detect_utils import detect, load_model, postproc_detections\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_axis(c0, c1, pad, cmax):\n",
    "    c0 = max(0, c0 - pad)\n",
    "    c1 = min(cmax, c1 + pad)\n",
    "    return c0, c1, c1 - c0\n",
    "\n",
    "\n",
    "@njit\n",
    "def expand_bbox(bbox, pct):\n",
    "    bbox = np.copy(bbox)\n",
    "    bbox[:2] *= 1 - pct\n",
    "    bbox[2:] *= 1 + pct\n",
    "    return bbox\n",
    "\n",
    "\n",
    "@njit\n",
    "def crop_face(img, bbox, pad_pct=0.05, square=True):\n",
    "    img_h, img_w, _ = img.shape\n",
    "    \n",
    "    if pad_pct > 0:\n",
    "        bbox = expand_bbox(bbox, pad_pct)\n",
    "        \n",
    "    x0, y0, x1, y1 = bbox.astype(np.int16)\n",
    "    \n",
    "    if square:\n",
    "        w, h = x1 - x0, y1 - y0\n",
    "        if w > h:\n",
    "            pad = (w - h) // 2\n",
    "            y0, y1, h = calc_axis(y0, y1, pad, img_h)\n",
    "        elif h > w:\n",
    "            pad = (h - w) // 2\n",
    "            x0, x1, w = calc_axis(x0, x1, pad, img_w)\n",
    "    \n",
    "    size = min(w, h)\n",
    "    face = img[y0:y1, x0:x1][:size, :size]\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_num_faces(num_faces, frac_thresh=0.25):\n",
    "    avg = num_faces.mean()\n",
    "    fraction, integral = np.modf(avg)\n",
    "    rounded = integral if fraction < frac_thresh else integral + 1\n",
    "    return int(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoPipe(dali.pipeline.Pipeline):\n",
    "    def __init__(self, filenames: List[str], seq_len=30, stride=10, \n",
    "                 batch_size=1, num_threads=1, device_id=0):\n",
    "        super(VideoPipe, self).__init__(\n",
    "            batch_size, num_threads, device_id, seed=3)\n",
    "        self.input = dali.ops.VideoReader(\n",
    "            device='gpu', filenames=filenames, \n",
    "            sequence_length=seq_len, stride=stride,\n",
    "            shard_id=0, num_shards=1)\n",
    "\n",
    "    def define_graph(self):\n",
    "        output = self.input(name='reader')\n",
    "        return output\n",
    "    \n",
    "    \n",
    "def get_file_list(df: pd.DataFrame, start: int, end: int, \n",
    "                  base_dir:str=DATA_DIR) -> List[str]:\n",
    "    path_fn = lambda row: os.path.join(base_dir, row.dir, row.name)\n",
    "    return df.iloc[start:end].apply(path_fn, axis=1).values.tolist()\n",
    "\n",
    "\n",
    "def build_data_iter(files: List[str]):\n",
    "    pipe = VideoPipe(files)\n",
    "    pipe.build()\n",
    "    return DALIGenericIterator([pipe], ['images'], len(files))\n",
    "\n",
    "\n",
    "def init_detector(cfg, weights, use_cpu=False):\n",
    "    cfg['pretrain'] = False\n",
    "    net = RetinaFace(cfg=cfg, phase='test')\n",
    "    net = load_model(net, weights, use_cpu)\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "\n",
    "def mkdirs(base_dir, chunk_dirs):\n",
    "    for chunk_dir in chunk_dirs:\n",
    "        dir_path = os.path.join(base_dir, chunk_dir)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_imgs(sample):\n",
    "    n, h, w, c = sample.shape\n",
    "    \n",
    "    imgs = sample.float()\n",
    "    imgs -= torch.tensor([104, 117, 123], device=imgs.device)\n",
    "    imgs = imgs.permute(0, 3, 1, 2)\n",
    "\n",
    "    scale = torch.tensor([w, h, w, h])\n",
    "    return imgs, scale\n",
    "\n",
    "\n",
    "def detect(sample, model, cfg, device):\n",
    "    bs = cfg['batch_size']\n",
    "    num_frames, height, width, ch = sample.shape\n",
    "    imgs, scale = prepare_imgs(sample)\n",
    "\n",
    "    priorbox = PriorBox(cfg, image_size=(height, width))\n",
    "    priors = priorbox.forward().to(device)\n",
    "    scale = scale.to(device)\n",
    "\n",
    "    detections = []\n",
    "    for start in range(0, num_frames, bs):\n",
    "        end = start + bs\n",
    "        imgs_batch = imgs[start:end] #.to(device)\n",
    "        with torch.no_grad():\n",
    "            loc, conf, landms = model(imgs_batch)\n",
    "        imgs_batch, landms = None, None\n",
    "        dets = postproc_detections(loc, conf, priors, scale, cfg)\n",
    "        detections.append(dets)\n",
    "        loc, conf = None, None\n",
    "    \n",
    "    return np.vstack(detections) if len(detections) > 1 else detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "        start=0, end=None, \n",
    "        num_frames_fake=30, num_frames_real=120,\n",
    "        use_cpu=False, bs=32, verbose=False,\n",
    "        base_dir=BASE_DIR, data_dir=DATA_DIR, save_dir=SAVE_DIR):\n",
    "    df = read_labels(data_dir)\n",
    "    mkdirs(save_dir, df['dir'].unique())\n",
    "    \n",
    "    device = torch.device(\"cpu\" if use_cpu else \"cuda\")\n",
    "    weights_mnet = os.path.join(base_dir, 'data/weights/mobilenet0.25_Final.pth')\n",
    "    cfg = {**cfg_mnet, 'batch_size': bs}\n",
    "    detector = init_detector(cfg, weights_mnet, use_cpu).to(device)\n",
    "    \n",
    "    if end is None:\n",
    "        end = len(df)\n",
    "        \n",
    "    num_frames = num_frames_fake\n",
    "    files = get_file_list(df, start, end)\n",
    "    pipe = VideoPipe(files, seq_len=num_frames, stride=300//num_frames)\n",
    "    pipe.build()\n",
    "    data_iter = DALIGenericIterator([pipe], ['images'], len(files))\n",
    "        \n",
    "    for idx, batch in tqdm(enumerate(data_iter), total=(end-start)):\n",
    "        meta = df.iloc[idx]\n",
    "        # fake = bool(meta['label'])\n",
    "        \n",
    "        sample_dir = os.path.join(save_dir, meta.dir, meta.name[:-4])\n",
    "        if not os.path.isdir(sample_dir):\n",
    "            os.mkdir(sample_dir)\n",
    "        if verbose:\n",
    "            t0 = time.time()\n",
    "        \n",
    "        images = batch[0]['images'].squeeze(0)\n",
    "        detections = detect(images, detector, cfg_mnet, device)\n",
    "        num_faces = np.array(list(map(len, detections)), dtype=np.uint8)\n",
    "        max_faces_per_frame = round_num_faces(num_faces, frac_thresh=0.25)\n",
    "        images = images.cpu().numpy()\n",
    "    \n",
    "        for f in range(num_frames):\n",
    "            for det in detections[f][:max_faces_per_frame]:\n",
    "                face = crop_face(images[f], det[:4])\n",
    "                file_path = os.path.join(sample_dir, '%03d.png' % f)\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_RGB2BGR)\n",
    "                # cv2.imwrite(file_path, face)\n",
    "        detections = None\n",
    "        # gc.collect()\n",
    "        \n",
    "        if verbose:\n",
    "            t1 = time.time()\n",
    "            print('[%6d][%.02f s] %s' % (idx, t1 - t0, sample_dir))\n",
    "    print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/dmitry/projects/dfdc/data/weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1751bdc1cb34097a376eba01996ffa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0][1.18 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/vkketnrfud\n",
      "[     1][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/tnsaqegyqt\n",
      "[     2][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/jcwkemycdm\n",
      "[     3][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/lnpsnoufkq\n",
      "[     4][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/rdfdbmyrqm\n",
      "[     5][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/otyrbsrkhn\n",
      "[     6][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/zmlpmfbryq\n",
      "[     7][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/sjhdwvfdbi\n",
      "[     8][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/npbreznxbl\n",
      "[     9][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/khoogmqdci\n",
      "[    10][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/zewjjvygcr\n",
      "[    11][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/qxfhktbwli\n",
      "[    12][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/yfihpubaxh\n",
      "[    13][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/fheautpznj\n",
      "[    14][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/vlyncoavxo\n",
      "[    15][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/wtykulolsd\n",
      "[    16][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/swljyvwykf\n",
      "[    17][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ctusyabydj\n",
      "[    18][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/lnqttvbefa\n",
      "[    19][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/inwjmrkgid\n",
      "[    20][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ekectxegkf\n",
      "[    21][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/jksqkdgclz\n",
      "[    22][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/xqxmeaetvc\n",
      "[    23][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/wuuvcuozwm\n",
      "[    24][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/kimxcwwkej\n",
      "[    25][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/tzcuzyosrc\n",
      "[    26][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/bdqffmwxqh\n",
      "[    27][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/xajzgrabnj\n",
      "[    28][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/lxvavsmyru\n",
      "[    29][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/oouvrspxmb\n",
      "[    30][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/rwqzraylnn\n",
      "[    31][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/jnfnwuvutq\n",
      "[    32][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/qfzxsyfdxg\n",
      "[    33][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ugcmhosdjs\n",
      "[    34][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/bfpwkwfwvq\n",
      "[    35][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/auzoiwvcym\n",
      "[    36][0.47 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/zfhguufzut\n",
      "[    37][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ltbzaimzmh\n",
      "[    38][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/hfnrljsphk\n",
      "[    39][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ibllwydbxg\n",
      "[    40][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/jtqstsniyh\n",
      "[    41][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/saqqigkyhg\n",
      "[    42][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/uvskkqzull\n",
      "[    43][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/fakxwnyyql\n",
      "[    44][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ibxkhtrmdq\n",
      "[    45][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/vmszbwofgp\n",
      "[    46][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/hvxbzwetvm\n",
      "[    47][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ufynlwmnos\n",
      "[    48][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/bxgyxslimt\n",
      "[    49][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/stwvmpdodl\n",
      "[    50][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/slnvjmpqxh\n",
      "[    51][0.47 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/dqfzodtstf\n",
      "[    52][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/zhomicrvyw\n",
      "[    53][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/aspaowlgbo\n",
      "[    54][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/qjyequmrfi\n",
      "[    55][0.47 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ehnadojbix\n",
      "[    56][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/hxsnyyrgwo\n",
      "[    57][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/bmlesleubu\n",
      "[    58][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/mgagdgincp\n",
      "[    59][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/fmkgoxapzt\n",
      "[    60][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/zbriaewnmi\n",
      "[    61][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/egguywfami\n",
      "[    62][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/licuyrxdia\n",
      "[    63][0.47 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/jdhxyyrdit\n",
      "[    64][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/eixhwihtgm\n",
      "[    65][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ramotheuuu\n",
      "[    66][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/kkiwwwgixc\n",
      "[    67][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/kaoouztuav\n",
      "[    68][0.47 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/cotsihcdmg\n",
      "[    69][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/uaixvsxxyi\n",
      "[    70][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/hitjkrjdbm\n",
      "[    71][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/dhobwtvijp\n",
      "[    72][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/brcwfkskbu\n",
      "[    73][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/tjxunamuze\n",
      "[    74][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/tccapvdmmv\n",
      "[    75][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/budabfnbql\n",
      "[    76][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/yjdmyvbkhm\n",
      "[    77][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/kbdgkojhvh\n",
      "[    78][0.47 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/crgedimfpc\n",
      "[    79][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/qyvzuyhkju\n",
      "[    80][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/iosfkthgtj\n",
      "[    81][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/bpvmtzmxpa\n",
      "[    82][0.49 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/igfhuqfvsk\n",
      "[    83][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ztpoqnifoa\n",
      "[    84][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/xwmrrppsml\n",
      "[    85][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/bxrxrggcnq\n",
      "[    86][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/cfycdpkjrt\n",
      "[    87][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ppapefxjki\n",
      "[    88][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/uaksqasofl\n",
      "[    89][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/aieztoondm\n",
      "[    90][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/gppcoesosf\n",
      "[    91][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/crkmmnhiam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    92][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/aknpmbdksv\n",
      "[    93][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/ymcircfnnm\n",
      "[    94][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/djmluqgtqy\n",
      "[    95][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/javaidijkz\n",
      "[    96][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/cseriybaqt\n",
      "[    97][0.48 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/exkoqwpzpl\n",
      "[    98][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/rzrzhdjahm\n",
      "[    99][0.46 s] /home/dmitry/projects/dfdc/data/dfdc-crops/dfdc_train_part_22/vwwqmjqrmv\n",
      "\n",
      "DONE\n",
      "CPU times: user 52.6 s, sys: 14.8 s, total: 1min 7s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "prepare_data(start=0, end=100, bs=30, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
