{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_block(in_ch: int, out_ch: int, kernel=3, \n",
    "              stride=2, pad=0, bn=True):\n",
    "    conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel, \n",
    "                     stride=stride, padding=pad)\n",
    "    relu = nn.ReLU(inplace=True)\n",
    "    if bn:\n",
    "        layers = [conv, nn.BatchNorm2d(out_ch), relu]\n",
    "    else:\n",
    "        layers = [conv, relu]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel=3, \n",
    "                 scale=2, pad=0, bn=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = partial(F.interpolate, \n",
    "                                scale_factor=scale, \n",
    "                                mode='nearest')\n",
    "        conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel, \n",
    "                         stride=1, padding=pad)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        if bn:\n",
    "            layers = [conv, nn.BatchNorm2d(out_ch), relu]\n",
    "        else:\n",
    "            layers = [conv, relu]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_old(x: Tensor, y: Tensor) -> Tensor:\n",
    "    N, C, H, W = x.shape\n",
    "    half_C = C // 2\n",
    "\n",
    "    low  = half_C * y\n",
    "    high = half_C * (y + 1)\n",
    "\n",
    "    x = x.clone()\n",
    "    for i in range(N):\n",
    "        x[i, low[i]:high[i]] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(h: Tensor, y: Tensor) -> Tensor:\n",
    "    N, C, H, W = h.shape\n",
    "    y = y.reshape(N, 1, 1, 1)\n",
    "    \n",
    "    h0, h1 = h.chunk(2, dim=1)\n",
    "    h0 = h0 * (1 - y)\n",
    "    h1 = h1 * y\n",
    "    h = torch.cat([h0, h1], dim=1)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(h: Tensor, y: Tensor) -> Tensor:\n",
    "    N, C, H, W = h.shape\n",
    "\n",
    "    y = y.reshape(N, 1, 1, 1)\n",
    "    h0, h1 = h.chunk(2, dim=1)\n",
    "    a = h0 * (1 - y) + h1 * y\n",
    "    \n",
    "    n_el = C * H * W / 2\n",
    "    a = a.abs().sum((1, 2, 3)) / n_el\n",
    "    \n",
    "    # For simplicity, and without losing generality, \n",
    "    # we constrain a(x) to be equal to 1\n",
    "    return a.clamp_max_(1).ceil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tensor([\n",
    "    [1,1,0,  1,1,0],\n",
    "    [0,0,0,  0,0,0],\n",
    "    [1,0,1,  0,1,0],\n",
    "    [1,1,1,  0,0,0],\n",
    "    [0,0,0,  1,1,1]\n",
    "], dtype=torch.float32, requires_grad=True)[:,:,None,None]\n",
    "\n",
    "y = torch.tensor([1, 0, 1, 0, 1])\n",
    "\n",
    "all_neg = torch.zeros(y.size(0), dtype=torch.int64)\n",
    "all_pos = torch.ones(y.size(0), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 1., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1.]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.reshape(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1.]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(h, all_pos).reshape(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0., 1.], grad_fn=<CeilBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act(h, all_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(h, all_neg).reshape(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 0.], grad_fn=<CeilBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act(h, all_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1.]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(h, y).reshape(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 1.], grad_fn=<CeilBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act(h, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L_{ACT} =\n",
    "\\sum_{x ∈ S_0}\n",
    "|a_0(x) − 1| + |a_1(x)| +\n",
    "\\sum_{x ∈ S_1}\n",
    "|a_1(x) − 1| + |a_0(x)|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(n: int) -> Tensor:\n",
    "    return torch.zeros(n, dtype=torch.int64)\n",
    "\n",
    "\n",
    "def ones(n: int) -> Tensor:\n",
    "    return torch.ones(n, dtype=torch.int64)\n",
    "\n",
    "\n",
    "def act_loss(x: Tensor, y: Tensor) -> Tensor:\n",
    "    pos = y.nonzero().reshape(-1)\n",
    "    neg = (y - 1).nonzero().reshape(-1)\n",
    "    x0, x1 = x[neg], x[pos]\n",
    "    n0, n1 = x0.size(0), x1.size(0)\n",
    "    \n",
    "    a0_x0 = act(x0, zeros(n0))\n",
    "    a1_x0 = act(x0, ones(n0))\n",
    "    \n",
    "    a1_x1 = act(x1, ones(n1))\n",
    "    a0_x1 = act(x1, zeros(n1))\n",
    "    \n",
    "    neg_loss = (a0_x0 - 1).abs() + a1_x0\n",
    "    pos_loss = (a1_x1 - 1).abs() + a0_x1\n",
    "\n",
    "    return (neg_loss.sum() + pos_loss.sum()) / y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6000, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_loss(h, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reconstruction_loss(x: Tensor, x_hat: Tensor) -> Tensor:\n",
    "#     return (x - x_hat).abs().sum() / x.numel()\n",
    "\n",
    "\n",
    "def rec_loss(x: Tensor, x_hat: Tensor) -> Tensor:\n",
    "    return F.l1_loss(x_hat, x, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, depth: int, size=8, pad=1):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Autoencoder._build_encoder(in_ch, depth, size, pad)\n",
    "        self.decoder = Autoencoder._build_decoder(in_ch, depth, size, pad)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _build_encoder(in_ch: int, depth: int, size: int, pad: int) -> nn.Module:        \n",
    "        stem = enc_block(in_ch, size, stride=1, pad=pad, bn=False)\n",
    "        main = [enc_block(size * 2**i, size * 2**(i+1), pad=pad) \n",
    "                for i in range(0, depth - 1)]\n",
    "        return nn.Sequential(stem, *main)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_decoder(out_ch: int, depth: int, size: int, pad: int) -> nn.Module:\n",
    "        main = [DecoderBlock(size * 2**(i+1), size * 2**i, pad=pad) \n",
    "                for i in sorted(range(0, depth - 1), reverse=True)]\n",
    "        last = nn.Conv2d(size, out_ch, 3, stride=1, padding=pad)\n",
    "        return nn.Sequential(*main, last, nn.Tanh())\n",
    "        \n",
    "    def forward(self, x, y) -> Tuple[Tensor, Tensor]:\n",
    "        h = self.encoder(x)\n",
    "        hc = select(h, y)\n",
    "        x_hat = self.decoder(hc)\n",
    "        return h, x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DecoderBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder(3, 5, pad=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 128, 16, 16]), torch.Size([5, 3, 256, 256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "x = torch.rand((N, 3, 256, 256))\n",
    "y = torch.randint(2, (N,))\n",
    "\n",
    "h, x_hat = model(x, y)\n",
    "\n",
    "h.shape, x_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1., grad_fn=<DivBackward0>),\n",
       " tensor(0.5113, grad_fn=<L1LossBackward>),\n",
       " tensor(1.0511, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_l = act_loss(h, y)\n",
    "r_l = rec_loss(x, x_hat)\n",
    "loss = a_l + 0.1 * r_l\n",
    "\n",
    "a_l, r_l, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 256\n",
    "depth = 5\n",
    "\n",
    "emb_size = img_size / 2**(depth-1)\n",
    "\n",
    "emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FakeDetector(nn.Module):\n",
    "#     def __init__(self, input_size: Tuple[int, int], enc_depth: int):\n",
    "#         \"\"\"\n",
    "#         Params:\n",
    "#         input_size - Tuple of (num_frames, img_size)\n",
    "#         \"\"\"\n",
    "#         super(FakeDetector, self).__init__()\n",
    "        \n",
    "#         n_frames, img_size = input_size\n",
    "#         self.autoenc = FakeDetector._build_autoenc(img_size, enc_depth)\n",
    "#         # self.sequence = nn.GRU()\n",
    "        \n",
    "    \n",
    "#     @staticmethod\n",
    "#     def _build_autoenc(img_size: int, depth: int):\n",
    "#         if not img_size % 32:\n",
    "#             raise AttributeError('Image size should be a multiple of 32')  \n",
    "#         size = img_size // 32\n",
    "#         return Autoencoder(in_ch=3, depth=depth, size=size, pad=1)\n",
    "        \n",
    "    \n",
    "#     def forward(self, x: Tensor, y: Tensor):\n",
    "#         N, F, C, H, W = x.shape\n",
    "#         embeds, xs_hat = [], []\n",
    "        \n",
    "#         for i in range(F):\n",
    "#             emb, x_hat = self.autoenc(x[:,i], y)\n",
    "#             embeds.append(emb)\n",
    "#             xs_hat.append(x_hat)\n",
    "        \n",
    "#         return h, x_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle] *",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
